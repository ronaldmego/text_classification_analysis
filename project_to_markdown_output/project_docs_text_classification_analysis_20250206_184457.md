Project Documentation Summary
=========================
Root Directory: C:\Users\ronal\APPs\text_classification_analysis
Files Analyzed: 6
Total Size: 12.23 KB
Timestamp: 2025-02-06 18:44:57

Skipped Files Sample:
-------------------
- file too large (2299.4KB): data\mind_news_classification.csv
- unknown type (4 files):
  ‚Ä¢ data\mind_news_classification_100.csv
  ‚Ä¢ outputs\sentiment_analysis_20250206_183722.csv
  ‚Ä¢ outputs\sentiment_analysis_20250206_184015.csv
  ‚Ä¢ outputs\sentiment_analysis_20250206_184337.csv
- file too large (22578.5KB): data\news.tsv
- binary file: sentiment_analysis.log

Directory Structure
==================

text_classification_analysis
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ mind_news_classification.csv
‚îÇ   ‚îú‚îÄ‚îÄ mind_news_classification_100.csv
‚îÇ   ‚îî‚îÄ‚îÄ news.tsv
‚îú‚îÄ‚îÄ download_data.py
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_analysis_20250206_183722.csv
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_analysis_20250206_184015.csv
‚îÇ   ‚îî‚îÄ‚îÄ sentiment_analysis_20250206_184337.csv
‚îú‚îÄ‚îÄ readme.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ sample_data.py
‚îú‚îÄ‚îÄ sentiment_analysis.log
‚îî‚îÄ‚îÄ sentiment_analyzer.py

File Contents
=============


================================================================================
File: app.py
================================================================================

import streamlit as st
import pandas as pd
import os
from datetime import datetime
from sentiment_analyzer import SentimentAnalyzer
import plotly.express as px

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="An√°lisis de Sentimientos",
    page_icon="üìä",
    layout="wide"
)

def create_output_dir():
    """Crea el directorio de outputs si no existe."""
    os.makedirs("outputs", exist_ok=True)

def generate_output_filename():
    """Genera un nombre de archivo √∫nico basado en la fecha y hora."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"outputs/sentiment_analysis_{timestamp}.csv"

def main():
    st.title("üìä Analizador de Sentimientos para T√≠tulos")
    st.write("Carga un archivo CSV y analiza el sentimiento de los t√≠tulos usando modelos de lenguaje.")

    # Crear directorio de outputs
    create_output_dir()

    # Subida de archivo
    uploaded_file = st.file_uploader("Elige un archivo CSV", type=['csv'])

    if uploaded_file is not None:
        # Leer el CSV
        df = pd.read_csv(uploaded_file)
        total_rows = len(df)
        
        st.write(f"üìÑ Archivo cargado: {uploaded_file.name}")
        st.write(f"üìä Total de t√≠tulos: {total_rows:,}")

        # Opciones de an√°lisis
        st.subheader("Configuraci√≥n del An√°lisis")
        analysis_type = st.radio(
            "Selecciona el tipo de an√°lisis:",
            ["Primeros 10 t√≠tulos", "Primeros 100 t√≠tulos", "Dataset completo"]
        )

        # Mapear selecci√≥n a l√≠mite
        limit_map = {
            "Primeros 10 t√≠tulos": 10,
            "Primeros 100 t√≠tulos": 100,
            "Dataset completo": None
        }
        limit = limit_map[analysis_type]

        # Tama√±o del batch
        batch_size = st.slider("Tama√±o del batch", min_value=10, max_value=100, value=50, step=10)

        if st.button("üöÄ Iniciar An√°lisis", type="primary"):
            # Inicializar el analizador
            analyzer = SentimentAnalyzer(batch_size=batch_size)
            
            # Contenedores para la visualizaci√≥n en tiempo real
            progress_container = st.empty()
            metrics_container = st.container()
            
            # Variables para el seguimiento
            processed = 0
            results = []
            start_time = datetime.now()

            # Procesar t√≠tulos
            total_to_process = limit if limit else total_rows
            progress_bar = st.progress(0)
            
            # Columnas para m√©tricas en tiempo real
            col1, col2, col3 = metrics_container.columns(3)
            positive_metric = col1.metric("Positivos", 0)
            neutral_metric = col2.metric("Neutros", 0)
            negative_metric = col3.metric("Negativos", 0)

            # Procesar por lotes
            df_to_process = df.head(limit) if limit else df
            
            for start_idx in range(0, len(df_to_process), batch_size):
                end_idx = min(start_idx + batch_size, len(df_to_process))
                batch = df_to_process.iloc[start_idx:end_idx]
                
                for _, row in batch.iterrows():
                    # Tomar el texto de la primera columna
                    text = row.iloc[0]
                    sentiment_code, sentiment = analyzer.analyze_sentiment(text)
                    
                    results.append({
                        'text': text,
                        'sentiment_code': sentiment_code,
                        'sentiment': sentiment
                    })
                    
                    processed += 1
                    
                    # Actualizar progreso y m√©tricas
                    progress = processed / total_to_process
                    progress_bar.progress(progress)
                    
                    # Actualizar m√©tricas
                    current_results = pd.DataFrame(results)
                    if not current_results.empty:
                        sentiment_counts = current_results['sentiment'].value_counts()
                        positive_metric.metric("Positivos", sentiment_counts.get('POSITIVE', 0))
                        neutral_metric.metric("Neutros", sentiment_counts.get('NEUTRAL', 0))
                        negative_metric.metric("Negativos", sentiment_counts.get('NEGATIVE', 0))
                    
                    # Actualizar informaci√≥n de progreso
                    elapsed_time = (datetime.now() - start_time).total_seconds()
                    rate = processed / elapsed_time if elapsed_time > 0 else 0
                    
                    progress_container.info(
                        f"‚è≥ Progreso: {processed:,}/{total_to_process:,} t√≠tulos "
                        f"({progress:.1%}) | "
                        f"Velocidad: {rate:.1f} t√≠tulos/segundo"
                    )

            # Crear DataFrame con resultados
            results_df = pd.DataFrame(results)
            
            # Guardar resultados
            output_file = generate_output_filename()
            results_df.to_csv(output_file, index=False, encoding='utf-8')
            
            # Mostrar resultados finales
            st.success(f"‚úÖ An√°lisis completado! Archivo guardado en: {output_file}")
            
            # Visualizaciones
            st.subheader("üìä Resultados del An√°lisis")
            
            # Gr√°fico de distribuci√≥n de sentimientos
            fig_pie = px.pie(
                results_df, 
                names='sentiment', 
                title='Distribuci√≥n de Sentimientos',
                color='sentiment',
                color_discrete_map={
                    'POSITIVE': '#28a745',
                    'NEUTRAL': '#17a2b8',
                    'NEGATIVE': '#dc3545'
                }
            )
            st.plotly_chart(fig_pie)
            
            # Mostrar nombre de la columna analizada
            st.info(f"üìù Columna analizada: {df.columns[0]}")
            
            # Mostrar datos en tabla
            st.subheader("üìã Muestra de Resultados")
            st.dataframe(
                results_df.style.set_properties(**{'text-align': 'left'})
            )

if __name__ == "__main__":
    main()



================================================================================
File: download_data.py
================================================================================

import os
import requests
import pandas as pd
from pathlib import Path
import zipfile
import io

def download_mind_dataset(save_path="./data"):
    """
    Descarga el dataset MIND desde el repositorio de Microsoft Recommenders.
    
    Args:
        save_path (str): Directorio donde guardar los datos
    Returns:
        pandas.DataFrame: DataFrame con t√≠tulos y categor√≠as
    """
    # Crear directorio si no existe
    save_path = Path(save_path)
    save_path.mkdir(parents=True, exist_ok=True)
    
    # URL del dataset
    url = "https://recodatasets.z20.web.core.windows.net/newsrec/MINDdemo_train.zip"
    
    print(f"Descargando dataset desde {url}...")
    try:
        # Descargar el archivo
        response = requests.get(url, timeout=30)
        
        response.raise_for_status()
        print("Descarga exitosa. Procesando archivo...")
        
        # Extraer y procesar el archivo zip
        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:
            news_file = next(
                (save_path / file for file in zip_ref.namelist() if file.endswith('news.tsv')),
                None
            )
            if news_file:
                zip_ref.extract(news_file.name, save_path)
                print(f"Archivo extra√≠do: {news_file}")
            else:
                raise ValueError("No se encontr√≥ el archivo news.tsv en el ZIP")
        
        # Leer y procesar el TSV
        print("Leyendo archivo TSV...")
        df = pd.read_csv(
            news_file, 
            sep='\t',
            header=None,
            names=['id', 'category', 'subcategory', 'title', 'abstract', 
                   'url', 'title_entities', 'abstract_entities']
        )
        
        # Crear y guardar DataFrame simplificado
        classification_df = df[['title', 'category', 'subcategory']]
        output_file = save_path / 'mind_news_classification.csv'
        classification_df.to_csv(output_file, index=False, encoding='utf-8')
        
        print(f"\nDataset procesado exitosamente. Shape: {classification_df.shape}")
        print(f"Datos guardados en: {output_file}")
        
        return classification_df
        
    except Exception as e:
        print(f"Error durante la descarga o procesamiento: {e}")
        print("\nPor favor, verifica que:")
        print("1. Tienes conexi√≥n a internet")
        print("2. El firewall no est√° bloqueando la conexi√≥n")
        print("3. Tienes permisos de escritura en el directorio de destino")
        return None

def main():
    df = download_mind_dataset()
    
    if df is not None:
        try:
            print("\nDistribuci√≥n de categor√≠as:")
            print(df['category'].value_counts())
            print("\nEjemplos de t√≠tulos por categor√≠a:")
            for category in df['category'].unique():
                print(f"\n{category.upper()}:")
                print(df[df['category'] == category]['title'].iloc[0])
        except Exception as e:
            print(f"Error al mostrar estad√≠sticas: {e}")

if __name__ == "__main__":
    main()



================================================================================
File: readme.md
================================================================================

# Guia

## Setup

Crear entorno virtual
```bash
python -m venv venv
```
Activar el entorno virtual
```bash
venv\Scripts\activate
```

Instalar dependencias
```bash
pip install -r requirements.txt
```

## Data

Los datos son de [Open-Data-Azure](https://learn.microsoft.com/en-us/azure/open-datasets/dataset-microsoft-news?tabs=azureml-opendatasets) y permiten hacer la extraccion de data para probar algoritmos de ML.

Los datos se descargan con el script `download_data.py`



================================================================================
File: requirements.txt
================================================================================

numpy==2.2.2
pandas==2.2.3
python-dateutil==2.9.0.post0
requests==2.32.3
langchain-ollama==0.2.2
python-dotenv==1.0.0
streamlit==1.42.0
plotly==6.0.0



================================================================================
File: sample_data.py
================================================================================

import pandas as pd

# Leer el CSV
df = pd.read_csv('data/mind_news_classification.csv')

# Tomar los primeros 100 registros
df_100 = df.head(100)

# Opcional: Guardar los 100 registros en un nuevo CSV
df_100.to_csv('data/mind_news_classification_100.csv', index=False)



================================================================================
File: sentiment_analyzer.py
================================================================================

from dotenv import load_dotenv
import os
from langchain_ollama import OllamaLLM
from langchain_core.prompts import PromptTemplate
import logging
from datetime import datetime

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('sentiment_analysis.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SentimentAnalyzer:
    SENTIMENT_CODES = {
        'POSITIVE': 1,
        'NEUTRAL': 0,
        'NEGATIVE': -1
    }
    
    def __init__(self, batch_size=50):
        """Inicializa el analizador de sentimientos."""
        load_dotenv()
        
        self.llm = OllamaLLM(
            model=os.getenv('OLLAMA_MODEL', 'phi4'),
            base_url=os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434'),
            temperature=0.1
        )
        
        self.batch_size = batch_size
        self.prompt_template = PromptTemplate(
            input_variables=["title"],
            template="""Analyze the sentiment of this news title:
"{title}"

Classify it into one of these categories:
- POSITIVE: For positive, optimistic, or uplifting content
- NEUTRAL: For factual, balanced, or objective content
- NEGATIVE: For negative, critical, or concerning content

Respond with ONLY ONE WORD: POSITIVE, NEUTRAL, or NEGATIVE."""
        )
        
    def analyze_sentiment(self, title: str) -> tuple[int, str]:
        """Analiza el sentimiento de un t√≠tulo y retorna (c√≥digo, sentimiento)."""
        try:
            prompt = self.prompt_template.format(title=title)
            response = self.llm.invoke(prompt).strip().upper()
            
            # Validar respuesta
            if response in self.SENTIMENT_CODES:
                logger.info(f"T√≠tulo: '{title[:100]}...' ‚Üí Sentimiento: {response}")
                return self.SENTIMENT_CODES[response], response
            
            # Por defecto, retornar NEUTRAL
            logger.warning(f"[RESPUESTA INV√ÅLIDA] '{response}' para t√≠tulo: '{title[:100]}...' ‚Üí Asignando: NEUTRAL")
            return self.SENTIMENT_CODES['NEUTRAL'], 'NEUTRAL'
            
        except Exception as e:
            logger.error(f"Error analizando t√≠tulo '{title}': {str(e)}")
            return self.SENTIMENT_CODES['NEUTRAL'], 'NEUTRAL'

